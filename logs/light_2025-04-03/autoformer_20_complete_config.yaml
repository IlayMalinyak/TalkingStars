{
  "light_transforms": "Compose(\n    moving_avg(kernel_size=13, stride=1)\n    ACF(max_lag=None)\n    Normalize(scheme='['std']', axis=0)\n    ToTensor\n)",
  "spec_transforms": "None",
  "train_dataset": "<dataset.dataset.KeplerDataset object at 0x7f6d5fec18b0>",
  "val_dataset": "<dataset.dataset.KeplerDataset object at 0x7f6d5fec22d0>",
  "test_dataset": "<dataset.dataset.KeplerDataset object at 0x7f6d5fec1fd0>",
  "model_args": "<util.utils.Container object at 0x7f6d5ff79940>",
  "model": "DistributedDataParallel(\n  (module): Model(\n    (decomp): series_decomp(\n      (moving_avg): moving_avg(\n        (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n      )\n    )\n    (enc_embedding): DataEmbedding_wo_pos(\n      (value_embedding): TokenEmbedding(\n        (tokenConv): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n      )\n      (position_embedding): PositionalEmbedding()\n      (temporal_embedding): TimeFeatureEmbedding(\n        (embed): Linear(in_features=1, out_features=64, bias=False)\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (dec_embedding): DataEmbedding_wo_pos(\n      (value_embedding): TokenEmbedding(\n        (tokenConv): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n      )\n      (position_embedding): PositionalEmbedding()\n      (temporal_embedding): TimeFeatureEmbedding(\n        (embed): Linear(in_features=1, out_features=64, bias=False)\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (encoder): Encoder(\n      (attn_layers): ModuleList(\n        (0-1): 2 x EncoderLayer(\n          (attention): AutoCorrelationLayer(\n            (inner_correlation): AutoCorrelation(\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (query_projection): Linear(in_features=64, out_features=64, bias=True)\n            (key_projection): Linear(in_features=64, out_features=64, bias=True)\n            (value_projection): Linear(in_features=64, out_features=64, bias=True)\n            (out_projection): Linear(in_features=64, out_features=64, bias=True)\n          )\n          (conv1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (conv2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (decomp1): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (decomp2): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (dropout): Dropout(p=0.2, inplace=False)\n        )\n      )\n      (norm): my_Layernorm(\n        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (decoder): Decoder(\n      (layers): ModuleList(\n        (0-1): 2 x DecoderLayer(\n          (self_attention): AutoCorrelationLayer(\n            (inner_correlation): AutoCorrelation(\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (query_projection): Linear(in_features=64, out_features=64, bias=True)\n            (key_projection): Linear(in_features=64, out_features=64, bias=True)\n            (value_projection): Linear(in_features=64, out_features=64, bias=True)\n            (out_projection): Linear(in_features=64, out_features=64, bias=True)\n          )\n          (cross_attention): AutoCorrelationLayer(\n            (inner_correlation): AutoCorrelation(\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (query_projection): Linear(in_features=64, out_features=64, bias=True)\n            (key_projection): Linear(in_features=64, out_features=64, bias=True)\n            (value_projection): Linear(in_features=64, out_features=64, bias=True)\n            (out_projection): Linear(in_features=64, out_features=64, bias=True)\n          )\n          (conv1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (conv2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (decomp1): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (decomp2): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (decomp3): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (dropout): Dropout(p=0.2, inplace=False)\n          (projection): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n        )\n      )\n      (norm): my_Layernorm(\n        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (projection): Linear(in_features=64, out_features=1, bias=True)\n    )\n    (head): Sequential(\n      (0): Linear(in_features=64, out_features=16, bias=True)\n      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): GELU(approximate='none')\n      (3): Dropout(p=0.2, inplace=False)\n      (4): Linear(in_features=16, out_features=1, bias=True)\n    )\n  )\n)",
  "trainer": {
    "model": "DistributedDataParallel(\n  (module): Model(\n    (decomp): series_decomp(\n      (moving_avg): moving_avg(\n        (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n      )\n    )\n    (enc_embedding): DataEmbedding_wo_pos(\n      (value_embedding): TokenEmbedding(\n        (tokenConv): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n      )\n      (position_embedding): PositionalEmbedding()\n      (temporal_embedding): TimeFeatureEmbedding(\n        (embed): Linear(in_features=1, out_features=64, bias=False)\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (dec_embedding): DataEmbedding_wo_pos(\n      (value_embedding): TokenEmbedding(\n        (tokenConv): Conv1d(2, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n      )\n      (position_embedding): PositionalEmbedding()\n      (temporal_embedding): TimeFeatureEmbedding(\n        (embed): Linear(in_features=1, out_features=64, bias=False)\n      )\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (encoder): Encoder(\n      (attn_layers): ModuleList(\n        (0-1): 2 x EncoderLayer(\n          (attention): AutoCorrelationLayer(\n            (inner_correlation): AutoCorrelation(\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (query_projection): Linear(in_features=64, out_features=64, bias=True)\n            (key_projection): Linear(in_features=64, out_features=64, bias=True)\n            (value_projection): Linear(in_features=64, out_features=64, bias=True)\n            (out_projection): Linear(in_features=64, out_features=64, bias=True)\n          )\n          (conv1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (conv2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (decomp1): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (decomp2): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (dropout): Dropout(p=0.2, inplace=False)\n        )\n      )\n      (norm): my_Layernorm(\n        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (decoder): Decoder(\n      (layers): ModuleList(\n        (0-1): 2 x DecoderLayer(\n          (self_attention): AutoCorrelationLayer(\n            (inner_correlation): AutoCorrelation(\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (query_projection): Linear(in_features=64, out_features=64, bias=True)\n            (key_projection): Linear(in_features=64, out_features=64, bias=True)\n            (value_projection): Linear(in_features=64, out_features=64, bias=True)\n            (out_projection): Linear(in_features=64, out_features=64, bias=True)\n          )\n          (cross_attention): AutoCorrelationLayer(\n            (inner_correlation): AutoCorrelation(\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (query_projection): Linear(in_features=64, out_features=64, bias=True)\n            (key_projection): Linear(in_features=64, out_features=64, bias=True)\n            (value_projection): Linear(in_features=64, out_features=64, bias=True)\n            (out_projection): Linear(in_features=64, out_features=64, bias=True)\n          )\n          (conv1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n          (conv2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n          (decomp1): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (decomp2): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (decomp3): series_decomp(\n            (moving_avg): moving_avg(\n              (avg): AvgPool1d(kernel_size=(2401,), stride=(1,), padding=(1200,))\n            )\n          )\n          (dropout): Dropout(p=0.2, inplace=False)\n          (projection): Conv1d(64, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False, padding_mode=circular)\n        )\n      )\n      (norm): my_Layernorm(\n        (layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n      (projection): Linear(in_features=64, out_features=1, bias=True)\n    )\n    (head): Sequential(\n      (0): Linear(in_features=64, out_features=16, bias=True)\n      (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): GELU(approximate='none')\n      (3): Dropout(p=0.2, inplace=False)\n      (4): Linear(in_features=16, out_features=1, bias=True)\n    )\n  )\n)",
    "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    base_momentum: 0.85\n    betas: (0.95, 0.999)\n    capturable: False\n    decoupled_weight_decay: True\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    initial_lr: 1e-05\n    lr: 9.999999999999999e-06\n    max_lr: 0.0001\n    max_momentum: 0.95\n    maximize: False\n    min_lr: 1.0000000000000001e-07\n    weight_decay: 1e-06\n)",
    "criterion": "MSELoss()",
    "scaler": "<torch.cuda.amp.grad_scaler.GradScaler object at 0x7f6d3c47a4b0>",
    "grad_clip": false,
    "cos_inc": false,
    "output_dim": 1,
    "scheduler": "<torch.optim.lr_scheduler.OneCycleLR object at 0x7f6d3b2748f0>",
    "train_dl": "<torch.utils.data.dataloader.DataLoader object at 0x7f6d5ff91b20>",
    "val_dl": "<torch.utils.data.dataloader.DataLoader object at 0x7f6d5ff938f0>",
    "train_sampler": "<torch.utils.data.distributed.DistributedSampler object at 0x7f6d5ff92ba0>",
    "val_sampler": "<torch.utils.data.distributed.DistributedSampler object at 0x7f6d5ff91010>",
    "max_iter": Infinity,
    "device": 0,
    "world_size": 1,
    "exp_num": "light_2025-04-03",
    "exp_name": "lc_autoformer_20",
    "log_path": "/data/TalkingStars/logs",
    "best_state_dict": null,
    "plot_every": null,
    "logger": null,
    "range_update": null,
    "accumulation_step": 1,
    "wandb": false,
    "num_quantiles": 1,
    "update_func": "<function Trainer.<lambda> at 0x7f6d60af77e0>",
    "pred_len": 960,
    "label_len": 1440
  },
  "loss_fn": "MSELoss()",
  "optimizer": "AdamW (\nParameter Group 0\n    amsgrad: False\n    base_momentum: 0.85\n    betas: (0.95, 0.999)\n    capturable: False\n    decoupled_weight_decay: True\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    initial_lr: 1e-05\n    lr: 9.999999999999999e-06\n    max_lr: 0.0001\n    max_momentum: 0.95\n    maximize: False\n    min_lr: 1.0000000000000001e-07\n    weight_decay: 1e-06\n)"
}